{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1117be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import logging\n",
    "import pickle\n",
    "import string\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import Counter, OrderedDict, defaultdict as ddict\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from util import read_squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "be2497e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['question', 'context', 'id', 'answer'])\n",
      "<class 'dict'>\n",
      "<class 'list'>\n",
      "[\"What was Jill's mother's face burned by?\", 'What year did a lynch mod muder someone who they believed to be a warlock?', 'Whose corpse is in the morgue?']\n"
     ]
    }
   ],
   "source": [
    "duorc = read_squad('datasets/oodomain_train/duorc')\n",
    "\n",
    "print(duorc.keys())\n",
    "print(type(duorc))\n",
    "print(type(duorc['question']))\n",
    "print(duorc['question'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5d25b",
   "metadata": {},
   "source": [
    "# Synonym Replacement (SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f69fd2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/thomaslemenestrel/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/thomaslemenestrel/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6f9c4a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', \n",
    "              'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "              'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "              'himself', 'she', 'her', 'hers', 'herself', \n",
    "              'it', 'its', 'itself', 'they', 'them', 'their', \n",
    "              'theirs', 'themselves', 'what', 'which', 'who', \n",
    "              'whom', 'this', 'that', 'these', 'those', 'am', \n",
    "              'is', 'are', 'was', 'were', 'be', 'been', 'being', \n",
    "              'have', 'has', 'had', 'having', 'do', 'does', 'did',\n",
    "              'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or',\n",
    "              'because', 'as', 'until', 'while', 'of', 'at', \n",
    "              'by', 'for', 'with', 'about', 'against', 'between',\n",
    "              'into', 'through', 'during', 'before', 'after', \n",
    "              'above', 'below', 'to', 'from', 'up', 'down', 'in',\n",
    "              'out', 'on', 'off', 'over', 'under', 'again', \n",
    "              'further', 'then', 'once', 'here', 'there', 'when', \n",
    "              'where', 'why', 'how', 'all', 'any', 'both', 'each', \n",
    "              'few', 'more', 'most', 'other', 'some', 'such', 'no', \n",
    "              'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', \n",
    "              'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "88d889c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_replacement(words, n):\n",
    "    new_words = words.copy()\n",
    "    \n",
    "    # Skip the word if it is in the stop words or capitalized\n",
    "    random_word_list = list(set([word for word in words if word not in stop_words and word[0].isupper() == False]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(list(synonyms))\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            #print(\"replaced\", random_word, \"with\", synonym)\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n: #only replace up to n words\n",
    "            break\n",
    "\n",
    "    sentence = ' '.join(new_words)\n",
    "    new_words = sentence.split(' ')\n",
    "\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0c9ad1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word): \n",
    "        for l in syn.lemmas(): \n",
    "            synonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "            synonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
    "            synonyms.add(synonym) \n",
    "    if word in synonyms:\n",
    "        synonyms.remove(word)\n",
    "    return list(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b5d3ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset(data):\n",
    "\n",
    "    aug_qs = []\n",
    "    for i in range(len(data['question'])):\n",
    "        new_pair = []\n",
    "\n",
    "        question = duorc['question'][i]\n",
    "        context  = duorc['context'][i]    \n",
    "        id_      = duorc['id'][i]\n",
    "        answer   = duorc['answer'][i]\n",
    "\n",
    "        question = question.split(' ')\n",
    "        output = synonym_replacement(question, 3)\n",
    "        new_question = ' '.join(output)\n",
    "        \n",
    "        data['question'].append(new_question)\n",
    "        data['context'].append(context)\n",
    "        data['id'].append(id_)\n",
    "        data['answer'].append(answer)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278577c",
   "metadata": {},
   "source": [
    "### Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8c9bfe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "254\n",
      "What was Jill's mother's face burned by?\n",
      "What was Jill's mother's case burned out by?\n",
      "{'answer_start': [2476], 'text': ['acid']}\n",
      "{'answer_start': [2476], 'text': ['acid']}\n",
      "Who uses scientific skill over trickery?\n",
      "Who economic consumption scientific science over trickery?\n",
      "{'answer_start': [959], 'text': ['Merlin']}\n",
      "{'answer_start': [959], 'text': ['Merlin']}\n"
     ]
    }
   ],
   "source": [
    "print(len(duorc['question']))\n",
    "\n",
    "new_duorc = augment_dataset(duorc)\n",
    "\n",
    "print(len(new_duorc['question']))\n",
    "\n",
    "print(duorc['question'][0])\n",
    "print(new_duorc['question'][127])\n",
    "\n",
    "print(duorc['answer'][0])\n",
    "print(new_duorc['answer'][127])\n",
    "\n",
    "print(duorc['question'][10])\n",
    "print(new_duorc['question'][137])\n",
    "\n",
    "print(duorc['answer'][10])\n",
    "print(new_duorc['answer'][137])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2e2b376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(obj, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        json.dump(obj, f)\n",
    "    return\n",
    "\n",
    "#save_json(new_duorc, 'datasets/oodomain_train/new_duorc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:robustqa]",
   "language": "python",
   "name": "conda-env-robustqa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
