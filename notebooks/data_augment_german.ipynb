{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4eb3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/koloss/Desktop/CS224N/final_project/RobustQA\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "529bf21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f80df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45775a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dataset(args, datasets, data_dir, tokenizer, split_name, debug=-1):\n",
    "    datasets = datasets.split(',')\n",
    "    dataset_dict = None\n",
    "    dataset_name = ''\n",
    "    label = 0\n",
    "    for dataset in datasets:\n",
    "        dataset_name += f'_{dataset}'\n",
    "        dataset_dict_curr = util.read_squad(f'{data_dir}/{dataset}')\n",
    "        dataset_dict_curr['label'] = label\n",
    "        dataset_dict = util.merge(dataset_dict, dataset_dict_curr)\n",
    "        label += 1\n",
    "    data_encodings = read_and_process(args, tokenizer, dataset_dict, data_dir, dataset_name, split_name)\n",
    "    return util.QADataset(data_encodings, train=(split_name == 'train')), dataset_dict, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32932a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5d64aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = 'duorc,race'\n",
    "data_dir = 'datasets/oodomain_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f96e2081",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = datasets.split(',')\n",
    "dataset_dict = None\n",
    "dataset_name = ''\n",
    "label = 0\n",
    "for dataset in datasets:\n",
    "    dataset_name += f'_{dataset}'\n",
    "    dataset_dict_curr = util.read_squad(f'{data_dir}/{dataset}')\n",
    "    dataset_dict_curr['label'] = label\n",
    "    dataset_dict = util.merge(dataset_dict, dataset_dict_curr)\n",
    "    label += 1\n",
    "#data_encodings = read_and_process(args, tokenizer, dataset_dict, data_dir, dataset_name, split_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "dbf2fa7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['question', 'context', 'id', 'answer', 'label'])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "92ea1b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "changes=dict(zip([\" game \", \" set \"], [\" lame \", \" bet \"]))\n",
    "\n",
    "df = pd.DataFrame({x: dataset_dict[x] for x in dataset_dict if x not in ['label']})\n",
    "df['start_char'] = df.answer.apply(lambda x : x['answer_start'][0])\n",
    "df['end_char'] = df['start_char']+ df.answer.apply(lambda x : len(x['text'][0]))\n",
    "df['final_answer'] = [A[B:C] for A, B, C in zip(df.context, df['start_char'],df['end_char'])]\n",
    "df['context'] = df.context.str.strip().replace(changes,regex=True)\n",
    "\n",
    "##df['new_context'] = df.context.str.strip().replace(changes,regex=True)\n",
    "##df['new_answer'] = [A[B:C] for A, B, C in zip(df['new_context'], df['start_char'],df['end_char'])]\n",
    "new_dataset_dict = df[[i for i in dataset_dict.keys() if i!= 'label']].to_dict()\n",
    "new_dataset_dict ['label'] = dataset_dict['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3a5c9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[[i for i in dataset_dict.keys() if i!= 'label']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "95d284fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>final_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was Jill's mother's face burned by?</td>\n",
       "      <td>New Orleans, Louisiana, 1927. An enraged posse...</td>\n",
       "      <td>d94a42693350473581ff79dc91c91e04</td>\n",
       "      <td>{'answer_start': [2476], 'text': ['acid']}</td>\n",
       "      <td>2476</td>\n",
       "      <td>2480</td>\n",
       "      <td>acid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What year did a lynch mod muder someone who th...</td>\n",
       "      <td>New Orleans, Louisiana, 1927. An enraged posse...</td>\n",
       "      <td>f41dbe24bed44870a8ad36c87dda59a2</td>\n",
       "      <td>{'answer_start': [26], 'text': ['1927']}</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whose corpse is in the morgue?</td>\n",
       "      <td>New Orleans, Louisiana, 1927. An enraged posse...</td>\n",
       "      <td>34f8093a16b64c8097bdaa03cccdef37</td>\n",
       "      <td>{'answer_start': [2873], 'text': ['Mary-Anne']}</td>\n",
       "      <td>2873</td>\n",
       "      <td>2882</td>\n",
       "      <td>Mary-Anne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the name of the blind girl?</td>\n",
       "      <td>New Orleans, Louisiana, 1927. An enraged posse...</td>\n",
       "      <td>b6a13cac6289435697e8ff98d55854a9</td>\n",
       "      <td>{'answer_start': [3659], 'text': ['Emily']}</td>\n",
       "      <td>3659</td>\n",
       "      <td>3664</td>\n",
       "      <td>Emily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Whose corpse does Liza see?</td>\n",
       "      <td>New Orleans, Louisiana, 1927. An enraged posse...</td>\n",
       "      <td>52ffe790d24a41669c08a240c1d45114</td>\n",
       "      <td>{'answer_start': [2348], 'text': ['Jill']}</td>\n",
       "      <td>2348</td>\n",
       "      <td>2352</td>\n",
       "      <td>Jill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0           What was Jill's mother's face burned by?   \n",
       "1  What year did a lynch mod muder someone who th...   \n",
       "2                     Whose corpse is in the morgue?   \n",
       "3                What is the name of the blind girl?   \n",
       "4                        Whose corpse does Liza see?   \n",
       "\n",
       "                                             context  \\\n",
       "0  New Orleans, Louisiana, 1927. An enraged posse...   \n",
       "1  New Orleans, Louisiana, 1927. An enraged posse...   \n",
       "2  New Orleans, Louisiana, 1927. An enraged posse...   \n",
       "3  New Orleans, Louisiana, 1927. An enraged posse...   \n",
       "4  New Orleans, Louisiana, 1927. An enraged posse...   \n",
       "\n",
       "                                 id  \\\n",
       "0  d94a42693350473581ff79dc91c91e04   \n",
       "1  f41dbe24bed44870a8ad36c87dda59a2   \n",
       "2  34f8093a16b64c8097bdaa03cccdef37   \n",
       "3  b6a13cac6289435697e8ff98d55854a9   \n",
       "4  52ffe790d24a41669c08a240c1d45114   \n",
       "\n",
       "                                            answer  start_char  end_char  \\\n",
       "0       {'answer_start': [2476], 'text': ['acid']}        2476      2480   \n",
       "1         {'answer_start': [26], 'text': ['1927']}          26        30   \n",
       "2  {'answer_start': [2873], 'text': ['Mary-Anne']}        2873      2882   \n",
       "3      {'answer_start': [3659], 'text': ['Emily']}        3659      3664   \n",
       "4       {'answer_start': [2348], 'text': ['Jill']}        2348      2352   \n",
       "\n",
       "  final_answer  \n",
       "0         acid  \n",
       "1         1927  \n",
       "2    Mary-Anne  \n",
       "3        Emily  \n",
       "4         Jill  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c51a3c",
   "metadata": {},
   "source": [
    "## SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "56ec6c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/koloss/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/koloss/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "aebeef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5fbc69d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop words list\n",
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', \n",
    "\t\t\t'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "\t\t\t'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "\t\t\t'himself', 'she', 'her', 'hers', 'herself', \n",
    "\t\t\t'it', 'its', 'itself', 'they', 'them', 'their', \n",
    "\t\t\t'theirs', 'themselves', 'what', 'which', 'who', \n",
    "\t\t\t'whom', 'this', 'that', 'these', 'those', 'am', \n",
    "\t\t\t'is', 'are', 'was', 'were', 'be', 'been', 'being', \n",
    "\t\t\t'have', 'has', 'had', 'having', 'do', 'does', 'did',\n",
    "\t\t\t'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or',\n",
    "\t\t\t'because', 'as', 'until', 'while', 'of', 'at', \n",
    "\t\t\t'by', 'for', 'with', 'about', 'against', 'between',\n",
    "\t\t\t'into', 'through', 'during', 'before', 'after', \n",
    "\t\t\t'above', 'below', 'to', 'from', 'up', 'down', 'in',\n",
    "\t\t\t'out', 'on', 'off', 'over', 'under', 'again', \n",
    "\t\t\t'further', 'then', 'once', 'here', 'there', 'when', \n",
    "\t\t\t'where', 'why', 'how', 'all', 'any', 'both', 'each', \n",
    "\t\t\t'few', 'more', 'most', 'other', 'some', 'such', 'no', \n",
    "\t\t\t'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', \n",
    "\t\t\t'very', 's', 't', 'can', 'will', 'just', 'don', \n",
    "\t\t\t'should', 'now', '']\n",
    "\n",
    "#cleaning up text\n",
    "import re\n",
    "def get_only_chars(line):\n",
    "\n",
    "    clean_line = \"\"\n",
    "\n",
    "    line = line.replace(\"â€™\", \"\")\n",
    "    line = line.replace(\"'\", \"\")\n",
    "    line = line.replace(\"-\", \" \") #replace hyphens with spaces\n",
    "    line = line.replace(\"\\t\", \" \")\n",
    "    line = line.replace(\"\\n\", \" \")\n",
    "    line = line.lower()\n",
    "\n",
    "    for char in line:\n",
    "        if char in 'qwertyuiopasdfghjklzxcvbnm ':\n",
    "            clean_line += char\n",
    "        else:\n",
    "            clean_line += ' '\n",
    "\n",
    "    clean_line = re.sub(' +',' ',clean_line) #delete extra spaces\n",
    "    if clean_line[0] == ' ':\n",
    "        clean_line = clean_line[1:]\n",
    "    return clean_line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1a758462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def synonym_replacement(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\trandom_word_list = list(set([word for word in words if word not in stop_words]))\n",
    "\trandom.shuffle(random_word_list)\n",
    "\tnum_replaced = 0\n",
    "\tfor random_word in random_word_list:\n",
    "\t\tsynonyms = get_synonyms(random_word)\n",
    "\t\tif len(synonyms) >= 1:\n",
    "\t\t\tsynonym = random.choice(list(synonyms))\n",
    "\t\t\tnew_words = [synonym if word == random_word else word for word in new_words]\n",
    "\t\t\t#print(\"replaced\", random_word, \"with\", synonym)\n",
    "\t\t\tnum_replaced += 1\n",
    "\t\tif num_replaced >= n: #only replace up to n words\n",
    "\t\t\tbreak\n",
    "\n",
    "\t#this is stupid but we need it, trust me\n",
    "\tsentence = ' '.join(new_words)\n",
    "\tnew_words = sentence.split(' ')\n",
    "\n",
    "\treturn new_words\n",
    "\n",
    "def get_synonyms(word):\n",
    "\tsynonyms = set()\n",
    "\tfor syn in wordnet.synsets(word): \n",
    "\t\tfor l in syn.lemmas(): \n",
    "\t\t\tsynonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "\t\t\tsynonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
    "\t\t\tsynonyms.add(synonym) \n",
    "\tif word in synonyms:\n",
    "\t\tsynonyms.remove(word)\n",
    "\treturn list(synonyms)\n",
    "\n",
    "def eda(sentence, alpha_sr=0.1, alpha_ri=0, alpha_rs=0, p_rd=0, num_aug=9):\n",
    "\t\n",
    "\tsentence = get_only_chars(sentence)\n",
    "\twords = sentence.split(' ')\n",
    "\twords = [word for word in words if word is not '']\n",
    "\tnum_words = len(words)\n",
    "\t\n",
    "\taugmented_sentences = []\n",
    "\tnum_new_per_technique = int(num_aug/4)+1\n",
    "\n",
    "\t#sr\n",
    "\tif (alpha_sr > 0):\n",
    "\t\tn_sr = max(1, int(alpha_sr*num_words))\n",
    "\t\tfor _ in range(num_new_per_technique):\n",
    "\t\t\ta_words = synonym_replacement(words, n_sr)\n",
    "\t\t\taugmented_sentences.append(' '.join(a_words))\n",
    "\n",
    "\t#ri\n",
    "\tif (alpha_ri > 0):\n",
    "\t\tn_ri = max(1, int(alpha_ri*num_words))\n",
    "\t\tfor _ in range(num_new_per_technique):\n",
    "\t\t\ta_words = random_insertion(words, n_ri)\n",
    "\t\t\taugmented_sentences.append(' '.join(a_words))\n",
    "\n",
    "\t#rs\n",
    "\tif (alpha_rs > 0):\n",
    "\t\tn_rs = max(1, int(alpha_rs*num_words))\n",
    "\t\tfor _ in range(num_new_per_technique):\n",
    "\t\t\ta_words = random_swap(words, n_rs)\n",
    "\t\t\taugmented_sentences.append(' '.join(a_words))\n",
    "\n",
    "\t#rd\n",
    "\tif (p_rd > 0):\n",
    "\t\tfor _ in range(num_new_per_technique):\n",
    "\t\t\ta_words = random_deletion(words, p_rd)\n",
    "\t\t\taugmented_sentences.append(' '.join(a_words))\n",
    "\n",
    "\taugmented_sentences = [get_only_chars(sentence) for sentence in augmented_sentences]\n",
    "\tshuffle(augmented_sentences)\n",
    "\n",
    "\t#trim so that we have the desired number of augmented sentences\n",
    "\tif num_aug >= 1:\n",
    "\t\taugmented_sentences = augmented_sentences[:num_aug]\n",
    "\telse:\n",
    "\t\tkeep_prob = num_aug / len(augmented_sentences)\n",
    "\t\taugmented_sentences = [s for s in augmented_sentences if random.uniform(0, 1) < keep_prob]\n",
    "\n",
    "\t#append the original sentence\n",
    "\taugmented_sentences.append(sentence)\n",
    "\n",
    "\treturn augmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ce6d9c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What was Jill's mother's face burned by?\""
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = df.loc[0,'question']\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "96cfc71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what was jills mothers face sting by',\n",
       " 'what was jills mothers face glow by',\n",
       " 'what was jills mothers face up burned by',\n",
       " 'what was jills mothers face burned by ']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185425ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
